---
title: "Homework 6"
author: "Jake Vettoretti"
date: "2025-11-29"
output: github_document
---
```{r}
library(broom)
library(modelr)
library(tidyverse)
library(forcats)
library(p8105.datasets)
set.seed(1)
```

## Problem 1

```{r}
## Loading the data

homicides <- read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```


# Starting to clean and summarize

```{r}
homicides_clean =
  homicides |>
    mutate(
      city_state = str_c(city, ", ", state),
      solved = if_else(disposition == "Closed by arrest", 1, 0),
      victim_age = as.numeric(victim_age)
      ) |>
    filter(
      !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
      victim_race %in% c("White", "Black")
      )
```

# GLM for Baltimore

```{r}
# Filter to Baltimore
baltimore_data =
  homicides_clean |>
  filter(city_state == "Baltimore, MD")

# Fit logistic regression
baltimore_glm =
  glm(
    solved ~ victim_age + victim_sex + victim_race,
    data = baltimore_data,
    family = binomial
  )

# Tidy and extract adjusted OR for male vs female
baltimore_results =
  broom::tidy(
    baltimore_glm,
    exponentiate = TRUE,
    conf.int = TRUE
  ) |>
  filter(term == "victim_sexMale") |>
  select(term, estimate, conf.low, conf.high)

baltimore_results
```

# GLM for each city

```{r}
city_glm_results =
  homicides_clean |>
  group_by(city_state) |>
  nest() |>
  mutate(
    fit = map(
      data,
      ~ glm(
        solved ~ victim_age + victim_sex + victim_race,
        data = .x,
        family = binomial
      )
    ),
    tidy_fit = map(
      fit,
      ~ broom::tidy(
        .x,
        exponentiate = TRUE,
        conf.int = TRUE
      )
    )
  ) |>
  unnest(tidy_fit) |>
  filter(term == "victim_sexMale") |>
  select(city_state, term, estimate, conf.low, conf.high)

city_glm_results
```

# Plot that shows the estimated ORs and CIs for each city

```{r fig.width=8, fig.height=8}
city_glm_results |>
  ggplot(aes(
    x = estimate,
    y = fct_reorder(city_state, estimate)
  )) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "gray50") +
  geom_point(size = 2) +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = 0.2) +
  labs(
    title = "Adjusted Odds of a Homicide Being Solved (Male vs Female Victims)",
    subtitle = "Logistic regression for each city adjusted for age and race",
    x = "Adjusted Odds Ratio (Male vs Female)",
    y = NULL
  ) +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.y = element_text(size = 8)
  )

```

Comments: Most cities show adjusted odds ratios close to one, which means that after accounting for age and race the chance that a homicide is solved is similar for male and female victims. A few cities have odds ratios above one, suggesting higher odds of a solved case among male victims, while others fall below one, suggesting higher odds among female victims. Many cities also have wide confidence intervals, which indicates substantial uncertainty and likely smaller sample sizes. Overall, there is no clear or consistent pattern across cities, and most results suggest little difference in solve rates by victim sex once demographic factors are considered.

## Problem 2

# Bootstrap setup

```{r}
data("weather_df")

weather_clean =
  weather_df |>
  drop_na(tmax, tmin, prcp)

boot_results =
  weather_clean |>
  bootstrap(5000) |>
  mutate(
    fit   = map(strap, ~ lm(tmax ~ tmin + prcp, data = .x)),
    gl    = map(fit, glance),
    td    = map(fit, tidy),
    r_sq  = map_dbl(gl, "r.squared"),
    beta_ratio = map_dbl(
      td,
      ~ {
        b1 = .x |> filter(term == "tmin") |> pull(estimate)
        b2 = .x |> filter(term == "prcp") |> pull(estimate)
        b1 / b2
      }
    )
  ) |>
  select(r_sq, beta_ratio)
```

# Plot bootstrap

```{r}
boot_results |>
  pivot_longer(
    cols = c(r_sq, beta_ratio),
    names_to = "parameter",
    values_to = "estimate"
  ) |>
  ggplot(aes(x = estimate)) +
  geom_histogram(bins = 50, color = "white") +
  facet_wrap(~ parameter, scales = "free", nrow = 1) +
  labs(
    x = "Bootstrap estimate",
    y = "Count",
    title = "Bootstrap distributions of R^2 and beta1/beta2"
  ) +
  theme_minimal()
```


# 95% CI from bootstrap

```{r}
boot_results |>
  summarise(
    r2_low     = quantile(r_sq, 0.025),
    r2_high    = quantile(r_sq, 0.975),
    ratio_low  = quantile(beta_ratio, 0.025),
    ratio_high = quantile(beta_ratio, 0.975)
  )
```

Comments: 
The bootstrap distribution of (R^2) is tightly concentrated around 0.94, indicating that the linear model with tmin and prcp explains a consistent and high proportion of the variability in tmax across resamples. The 95 percent bootstrap interval for (R^2) (0.934 to 0.947) reflects this stability.

In contrast, the distribution of the ratio (\hat\beta_1 / \hat\beta_2) is much wider and strongly skewed. This reflects high uncertainty in the relative magnitudes of the effects of tmin and prcp. The 95 percent interval (−275 to −125) is very broad, showing that even though the ratio is consistently negative (because the estimated slope for precipitation is small and negative), its exact value is highly variable from sample to sample.

Overall, the bootstrap suggests that the overall model fit (R²) is very stable, while the ratio of coefficients is much more sensitive to sampling variation.

## Problem 3

# Part 1 

```{r}
birthweight =
  read_csv("birthweight.csv") |>
  janitor::clean_names() |>
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("male", "female")),
    frace   = factor(frace, levels = c(1,2,3,4,8,9),
                     labels = c("white","black","asian","puerto_rican","other","unknown")),
    mrace   = factor(mrace, levels = c(1,2,3,4,8),
                     labels = c("white","black","asian","puerto_rican","other")),
    malform = factor(malform, levels = c(0,1), labels = c("absent","present")),
    # parity is usually treated as numeric integer
    parity  = as.integer(parity)
  )

#Check missing data
birthweight_missing =
  birthweight |>
  summarize(across(everything(), ~ sum(is.na(.))))

birthweight_missing
```

# Part 2

```{r}
#Model

birthweight_model =
  birthweight |>
  lm(bwt ~ bhead + blength + gaweeks + ppbmi + smoken + babysex + mrace, data = _)

summary(birthweight_model)
```

Model equation:
bwt
=−5859.947+135.151(bhead) + 78.442(blength) + 12.328(gaweeks) + 5.171(ppbmi) − 4.302(smoken) + 31.311(babysex = female) − 141.600(mrace = black) − 103.215(mrace = asian) − 139.896(mrace = puerto_rican) − 141.600(mrace = black) −103.215(mrace = asian) − 139.896(mrace = puerto_rican)

Description of modeling process:
To model birthweight, I selected predictors based on biological plausibility and prior knowledge of factors that influence fetal growth. Head circumference, birth length, and gestational age are direct indicators of newborn size and maturity. Maternal pre-pregnancy BMI reflects nutritional status, and smoking during pregnancy is a well-established risk factor for reduced birthweight. I included baby sex and maternal race as demographic covariates that may influence birth outcomes. This approach balances scientific justification with interpretability.

```{r}
#Residual vs fitted plot

birthweight_residplot =
  birthweight |>
  add_predictions(birthweight_model) |>
  add_residuals(birthweight_model) |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, color = "red") +
  labs(
    x = "Fitted values",
    y = "Residuals",
    title = "Residuals vs Fitted Values for Birthweight Model"
  ) +
  theme_minimal()

birthweight_residplot
```

# Part 3

```{r}
#Cross validated model comparison

  # My model
model_main =
  lm(bwt ~ bhead + blength + gaweeks + ppbmi + smoken + babysex + mrace,
     data = birthweight)

  # Model A: length + gestational age, main effects only
model_simple =
  lm(bwt ~ blength + gaweeks, data = birthweight)

  # Model B: all interactions among head circumference, length, sex
model_interaction =
  lm(bwt ~ bhead * blength * babysex, data = birthweight)

#Cross validation using MCV
cv_df =
  crossv_mc(birthweight, 50) |>
  mutate(
    train = map(train, as_tibble),
    test  = map(test, as_tibble)
  )

#Fit all three models on training set
cv_results =
  cv_df |>
  mutate(
    fit_main = map(train,
                   ~ lm(bwt ~ bhead + blength + gaweeks + ppbmi +
                          smoken + babysex + mrace, data = .x)),
    fit_simple = map(train,
                     ~ lm(bwt ~ blength + gaweeks, data = .x)),
    fit_interaction = map(train,
                          ~ lm(bwt ~ bhead * blength * babysex, data = .x))
  )

#Compute RMSE
cv_results =
  cv_results |>
  mutate(
    rmse_main =
      map2_dbl(fit_main, test,
               ~ rmse(model = .x, data = .y)),

    rmse_simple =
      map2_dbl(fit_simple, test,
               ~ rmse(model = .x, data = .y)),

    rmse_interaction =
      map2_dbl(fit_interaction, test,
               ~ rmse(model = .x, data = .y))
  )

#Summarizing predicted error
cv_summary =
  cv_results |>
  summarise(
    main_rmse  = mean(rmse_main),
    simple_rmse = mean(rmse_simple),
    interaction_rmse = mean(rmse_interaction)
  )

cv_summary
```
Write up:

To compare the predictive performance of the three candidate models, I performed a 50-fold Monte Carlo cross-validation and computed the root mean squared error (RMSE) on each test set. The average RMSE values were:

Main-effects model: 278.18

Simple model (length and gestational age): 332.68

Full interaction model: 289.11

The main-effects model had the lowest RMSE, indicating the best predictive accuracy of the three. This suggests that including biologically relevant predictors such as head circumference, birth length, gestational age, maternal BMI, smoking, sex, and maternal race provides meaningful information for predicting birthweight.

The simple model had the highest RMSE, meaning that using only birth length and gestational age results in noticeably worse predictions. This is expected because birthweight is influenced by many maternal and infant characteristics beyond size and gestational age.

The interaction model performed better than the simple model but worse than the main-effects model. Adding all two-way and three-way interactions among head circumference, length, and sex increased the complexity without improving predictive accuracy, likely due to overfitting.

In summary, the main-effects model shows the best balance of model complexity and predictive performance for estimating birthweight in this dataset.









